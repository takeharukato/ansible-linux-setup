#!/usr/bin/env python3
# -*- mode: python; coding: utf-8; line-endings: unix -*-
# SPDX-License-Identifier: BSD-2-Clause
#
# This file is distributed under the two-clause BSD license.
# このファイルは2条項BSDライセンスの下で配布されています。
#
# BSD 2-Clause License
#
# Copyright (c) 2025, TAKEHARU KATO
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#1. Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
# OpenAI's ChatGPT partially generated this code.
# Author has modified some parts.
# OpenAIのChatGPTがこのコードの一部を生成しました。
# 著者が修正している部分があります。

"""Cilium Cluster Mesh 用の kubeconfig を統合するユーティリティです。

`kubectl` を用いて入力 kubeconfig を正規化し、クラスタ / コンテキスト /
ユーザ識別子を保持したまま 1 つの設定に統合します。名称が衝突した場合は
後続要素へ ``-2`` などのサフィックスを付与して解決します。
"""

from __future__ import annotations

import argparse
import gettext
import json
import logging
import subprocess
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, Union, cast

import yaml  # type: ignore[import]

LOGGER = logging.getLogger("create_uniq_kubeconfig")


LOCALE = gettext.translation("create_uniq_kubeconfig", fallback=True)
_ = LOCALE.gettext


DEFAULT_OUTPUT_FILENAME = "merged-kubeconfig.config"


JSONValue = Union[
    str,
    int,
    float,
    bool,
    None,
    Dict[str, "JSONValue"],
    List["JSONValue"],
]
JSONObject = Dict[str, JSONValue]
JSONArray = List[JSONValue]


class KubectlError(RuntimeError):
    """``kubectl`` 実行失敗を表す例外です。

    ラップ対象の ``kubectl`` コマンドが非ゼロ終了した際に送出されます。
    """


@dataclass
class FlattenedConfig:
    """正規化された kubeconfig 情報を保持するデータクラスです。

    統合処理で必要となる原本パスと整形済みデータをひとまとめに管理します。

    Attributes:
        source (Path): 元の kubeconfig ファイルパスです。
        data (JSONObject): 正規化済みの kubeconfig 辞書です。
    """

    source: Path
    data: JSONObject


def _extract_dicts(value: Optional[JSONValue]) -> List[JSONObject]:
    """リスト内の辞書要素だけを抽出します。

    任意のリストを受け取り、辞書型の要素のみを順序を保持したまま返します。

    Args:
        value (Optional[JSONValue]): 抽出対象の値です。

    Returns:
        List[JSONObject]: 辞書要素のみを含むリストです。

    Examples:
        >>> _extract_dicts([{'a': 1}, 'x'])
        [{'a': 1}]
    """

    if not isinstance(value, list):
        return []

    typed_value: List[JSONValue] = cast(List[JSONValue], value)

    result: List[JSONObject] = []
    for item in typed_value:
        if isinstance(item, dict):
            result.append(cast(JSONObject, item))
    return result


def parse_args(argv: Optional[Iterable[str]] = None) -> argparse.Namespace:
    """コマンドライン引数を解析します。

    指定がない場合は ``sys.argv`` をそのまま解析します。
    出力ファイルを明示しない場合は ``DEFAULT_OUTPUT_FILENAME`` を使用します。

    Args:
        argv (Optional[Iterable[str]]): 解析対象の引数。``None`` の場合は ``sys.argv`` を参照します。

    Returns:
        argparse.Namespace: 解析済みの引数オブジェクトです。

    Examples:
        >>> opts = parse_args(["--output", "merged.yaml", "a.kube", "b.kube"])
        >>> opts.output
        'merged.yaml'
        >>> default_opts = parse_args(["a.kube"])
        >>> default_opts.output
        'merged-kubeconfig.config'
    """

    parser = argparse.ArgumentParser(
        description=_("Merge multiple kubeconfig files into one output file."),
    )
    parser.add_argument(
        "kubeconfigs",
        metavar="KUBECONFIG",
        nargs="+",
        help=_("Paths to kubeconfig files to merge (will be processed in order)."),
    )

    parser.add_argument(
        "-o",
        "--output",
        default=DEFAULT_OUTPUT_FILENAME,
        help=_("Destination kubeconfig path (default: {default}).").format(
            default=DEFAULT_OUTPUT_FILENAME,
        ),
    )

    parser.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help=_("Increase log verbosity (repeat for more detail)."),
    )

    parsed_argv: Optional[Sequence[str]]
    if argv is None:
        parsed_argv = None
    else:
        parsed_argv = list(argv)

    return parser.parse_args(parsed_argv)


def setup_logging(verbosity: int) -> None:
    """ログ出力レベルを ``-v`` の指定回数に応じて設定します。

    目的に応じて ``DEBUG`` から ``WARNING`` までのレベルを自動的に切り替えます。

    Args:
        verbosity (int): ``-v`` の出現回数です。

    Examples:
        >>> setup_logging(0)
        >>> LOGGER.getEffectiveLevel() >= logging.WARNING
        True
    """

    if verbosity >= 2:
        level = logging.DEBUG
    elif verbosity == 1:
        level = logging.INFO
    else:
        level = logging.WARNING

    logging.basicConfig(
        level=level,
        format="[%(levelname)s] %(message)s",
    )


def run_kubectl(args: List[str]) -> str:
    """``kubectl`` を実行し、標準出力を文字列で返します。

    サブコマンドの出力だけを取得したい用途向けの薄いラッパーです。

    Args:
        args (List[str]): ``kubectl`` に渡す引数リストです。

    Returns:
        str: ``kubectl`` の標準出力です。

    Raises:
        KubectlError: ``kubectl`` が非ゼロで終了した場合に送出します。

    Examples:
        >>> from unittest import mock
        >>> with mock.patch('subprocess.run') as mocked:
        ...     mocked.return_value = mock.Mock(stdout='ok\n', stderr='', returncode=0)
        ...     run_kubectl(['version'])
        'ok\n'
    """

    cmd = ["kubectl", *args]
    LOGGER.debug(_("Running command: %s"), " ".join(cmd))
    try:
        completed = subprocess.run(
            cmd,
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
    except subprocess.CalledProcessError as exc:  # pragma: no cover - サブプロセス失敗経路
        LOGGER.error(_("kubectl failed: %s"), exc.stderr.strip())
        raise KubectlError(_("kubectl command failed")) from exc

    return completed.stdout


def flatten_kubeconfig(path: Path) -> FlattenedConfig:
    """指定されたファイルの正規化済み kubeconfig を取得します。

    ``kubectl config view`` の結果を解析して統合処理に適した辞書へ整形します。

    Args:
        path (Path): 読み込む kubeconfig ファイルパスです。

    Returns:
        FlattenedConfig: 正規化された kubeconfig データです。

    Raises:
        KubectlError: ``kubectl`` の実行に失敗した場合に送出します。
        RuntimeError: YAML 解析に失敗した場合、または構造が不正な場合に送出します。

    Examples:
        >>> from unittest import mock
        >>> yaml_text = 'apiVersion: v1\nclusters: []\ncontexts: []\nusers: []\n'
        >>> with mock.patch('create_uniq_kubeconfig.run_kubectl', return_value=yaml_text):
        ...     cfg = flatten_kubeconfig(Path('sample.kube'))
        >>> cfg.source.name
        'sample.kube'
    """

    args = ["config", "view", "--raw", "--flatten", f"--kubeconfig={path}"]
    stdout = run_kubectl(args)

    try:
        raw_data = yaml.safe_load(stdout)
    except yaml.YAMLError as exc:  # pragma: no cover - YAML 解析失敗経路
        raise RuntimeError(
            _("Failed to parse kubeconfig from {path}: {error}").format(
                path=path,
                error=exc,
            )
        ) from exc

    if raw_data is None:
        raw_data = {}

    if not isinstance(raw_data, dict):
        raise RuntimeError(
            _("Unexpected kubeconfig structure from {path}").format(path=path)
        )

    data: JSONObject = cast(JSONObject, raw_data)

    clusters_list = _extract_dicts(data.get("clusters"))
    contexts_list = _extract_dicts(data.get("contexts"))
    users_list = _extract_dicts(data.get("users"))

    cluster_count = len(clusters_list)
    context_count = len(contexts_list)
    user_count = len(users_list)

    LOGGER.debug(
        _("Loaded %s: clusters=%d contexts=%d users=%d"),
        path,
        cluster_count,
        context_count,
        user_count,
    )
    return FlattenedConfig(source=path, data=data)


def dict_signature(value: object) -> str:
    """入れ子辞書から安定した署名文字列を生成します。

    辞書の順序に依存しない比較を実現するために JSON へ正規化します。

    Args:
        value (object): 署名化する任意のシリアライズ可能オブジェクトです。

    Returns:
        str: JSON 表現による署名です。

    Examples:
        >>> dict_signature({'b': 2, 'a': 1})
        '{"a":1,"b":2}'
    """

    return json.dumps(value, sort_keys=True, separators=(",", ":"))


def ensure_unique_name(base: str, used: Dict[str, JSONObject]) -> str:
    """名称の重複を避けるため必要に応じてサフィックスを付与します。

    既存名称を衝突させずに利用できる候補を段階的に探索します。

    Args:
        base (str): 希望する名称です。
        used (Dict[str, JSONObject]): 既に使用されている名称の辞書です。

    Returns:
        str: 利用可能な一意の名称です。

    Examples:
        >>> ensure_unique_name('cluster', {})
        'cluster'
        >>> ensure_unique_name('cluster', {'cluster': {}})
        'cluster-2'
    """

    if base not in used:
        return base

    suffix = 2
    while True:
        candidate = f"{base}-{suffix}"
        if candidate not in used:
            return candidate
        suffix += 1


def merge_configs(configs: List[FlattenedConfig]) -> JSONObject:
    """正規化された kubeconfig 群を 1 つの辞書に統合します。

    クラスタ・ユーザ・コンテキストの重複を署名比較で排除しつつ結合します。

    Args:
        configs (List[FlattenedConfig]): 統合対象の kubeconfig 一覧です。

    Returns:
        JSONObject: 統合後の kubeconfig 辞書です。

    Examples:
        >>> simple_cfg = {
        ...     'apiVersion': 'v1',
        ...     'clusters': [{'name': 'c1', 'cluster': {'server': 'https://x'}}],
        ...     'contexts': [{'name': 'ctx', 'context': {'cluster': 'c1', 'user': 'u1'}}],
        ...     'users': [{'name': 'u1', 'user': {'token': 'abc'}}],
        ... }
        >>> merged = merge_configs([FlattenedConfig(Path('a'), simple_cfg)])
        >>> merged['clusters'][0]['name']
        'c1'
    """

    combined_clusters: JSONArray = []
    combined_contexts: JSONArray = []
    combined_users: JSONArray = []
    combined: JSONObject = {
        "apiVersion": "v1",
        "kind": "Config",
        "preferences": {},
        "clusters": combined_clusters,
        "contexts": combined_contexts,
        "users": combined_users,
    }

    cluster_by_name: Dict[str, JSONObject] = {}
    cluster_by_signature: Dict[str, str] = {}
    user_by_name: Dict[str, JSONObject] = {}
    user_by_signature: Dict[str, str] = {}
    context_by_name: Dict[str, JSONObject] = {}
    context_by_signature: Dict[str, str] = {}

    final_current_context: Optional[str] = None

    for _index, flattened in enumerate(configs):
        data = flattened.data

        preferences_value = data.get("preferences")
        if not combined["preferences"] and preferences_value:
            combined["preferences"] = preferences_value

        cluster_map: Dict[str, str] = {}
        cluster_entries = _extract_dicts(data.get("clusters"))
        for entry in cluster_entries:
            original_name_value = entry.get("name")
            cluster_data_value = entry.get("cluster")
            if not isinstance(original_name_value, str) or not isinstance(cluster_data_value, dict):
                LOGGER.debug(
                    _("Skipping malformed cluster entry in %s"),
                    flattened.source,
                )
                continue

            cluster_dict: JSONObject = cast(JSONObject, cluster_data_value)
            original_name = original_name_value

            signature = dict_signature(cluster_dict)
            existing_name = cluster_by_signature.get(signature)
            if existing_name:
                cluster_map[original_name] = existing_name
                continue

            target_name = ensure_unique_name(original_name, cluster_by_name)
            cluster_by_signature[signature] = target_name
            cluster_by_name[target_name] = cluster_dict
            cluster_map[original_name] = target_name
            combined_clusters.append({"name": target_name, "cluster": cluster_dict})

        user_map: Dict[str, str] = {}
        user_entries = _extract_dicts(data.get("users"))
        for entry in user_entries:
            original_name_value = entry.get("name")
            user_data_value = entry.get("user")
            if not isinstance(original_name_value, str) or not isinstance(user_data_value, dict):
                LOGGER.debug(
                    _("Skipping malformed user entry in %s"),
                    flattened.source,
                )
                continue

            user_dict: JSONObject = cast(JSONObject, user_data_value)
            original_name = original_name_value

            signature = dict_signature(user_dict)
            existing_name = user_by_signature.get(signature)
            if existing_name:
                user_map[original_name] = existing_name
                continue

            target_name = ensure_unique_name(original_name, user_by_name)
            user_by_signature[signature] = target_name
            user_by_name[target_name] = user_dict
            user_map[original_name] = target_name
            combined_users.append({"name": target_name, "user": user_dict})

        context_map: Dict[str, str] = {}
        context_entries = _extract_dicts(data.get("contexts"))
        for entry in context_entries:
            original_name_value = entry.get("name")
            context_data_value = entry.get("context")
            if not isinstance(original_name_value, str) or not isinstance(context_data_value, dict):
                LOGGER.debug(
                    _("Skipping malformed context entry in %s"),
                    flattened.source,
                )
                continue

            context_dict: JSONObject = cast(JSONObject, context_data_value)
            adjusted_context: JSONObject = context_dict.copy()
            original_name = original_name_value
            cluster_name = adjusted_context.get("cluster")
            user_name = adjusted_context.get("user")
            if isinstance(cluster_name, str) and cluster_name in cluster_map:
                adjusted_context["cluster"] = cluster_map[cluster_name]
            if isinstance(user_name, str) and user_name in user_map:
                adjusted_context["user"] = user_map[user_name]

            signature = dict_signature(adjusted_context)
            existing_name = context_by_signature.get(signature)
            if existing_name:
                context_map[original_name] = existing_name
                continue

            target_name = ensure_unique_name(original_name, context_by_name)
            context_by_signature[signature] = target_name
            context_by_name[target_name] = adjusted_context
            context_map[original_name] = target_name
            combined_contexts.append({"name": target_name, "context": adjusted_context})

        if final_current_context is None:
            source_current = data.get("current-context")
            if isinstance(source_current, str) and source_current:
                mapped_current = context_map.get(source_current)
                if mapped_current:
                    final_current_context = mapped_current
                elif source_current in context_by_name:
                    final_current_context = source_current

        LOGGER.info(
            _("Processed %s (clusters=%d, contexts=%d, users=%d)"),
            flattened.source,
            len(cluster_map),
            len(context_map),
            len(user_map),
        )

        if not cluster_map:
            LOGGER.warning(_("No clusters found in %s"), flattened.source)

    combined["current-context"] = final_current_context or ""
    return combined


def confirm_overwrite(path: Path) -> bool:
    """既存ファイルを上書きしてよいか利用者へ確認します。

    対話プロンプトへの回答が肯定の場合のみ上書き処理を許可します。

    Args:
        path (Path): 出力予定のファイルパスです。

    Returns:
        bool: 上書きを許可する場合は ``True``、それ以外は ``False`` です。

    Examples:
        >>> from unittest import mock
        >>> with mock.patch('builtins.input', return_value='y'):
        ...     confirm_overwrite(Path('out.yaml'))
        True
    """

    try:
        prompt = _("{} already exists. Overwrite? [y/N]: ").format(path)
        answer = input(prompt)
    except EOFError:
        return False

    return answer.strip().lower() in {"y", "yes"}


def write_output(path: Path, data: JSONObject) -> None:
    """統合済み kubeconfig をファイルへ書き出します。

    既存ディレクトリを自動的に作成し、安全な YAML 形式で永続化します。

    Args:
        path (Path): 出力先パスです。
        data (JSONObject): 書き込み対象の kubeconfig 辞書です。

    Examples:
        >>> import tempfile
        >>> with tempfile.TemporaryDirectory() as tmp:
        ...     out = Path(tmp) / 'merged.yaml'
        ...     write_output(out, {'apiVersion': 'v1'})
        ...     out.exists()
        True
    """

    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as handle:
        yaml.safe_dump(
            data,
            handle,
            default_flow_style=False,
            sort_keys=False,
        )


def main(argv: Optional[Iterable[str]] = None) -> int:
    """エントリーポイントとなるメイン処理です。

    引数解析からマージ処理、ファイル書き出しまで一連の操作を調整します。

    Args:
        argv (Optional[Iterable[str]]): CLI 引数。``None`` の場合は ``sys.argv`` を使用します。

    Returns:
        int: 正常終了時は ``0``、異常時は ``0`` 以外のコードです。

    Examples:
        >>> from unittest import mock
        >>> fake_yaml = 'apiVersion: v1\nclusters: []\ncontexts: []\nusers: []\n'
        >>> argv = ['--output', 'merged.yaml', 'a.kube']
        >>> with mock.patch('pathlib.Path.exists', side_effect=[True, False]):
        ...     with mock.patch('pathlib.Path.expanduser', side_effect=lambda self: self):
        ...         with mock.patch('pathlib.Path.resolve', side_effect=lambda self: self):
        ...             with mock.patch('create_uniq_kubeconfig.flatten_kubeconfig') as fl:
        ...                 fl.return_value = FlattenedConfig(Path('a.kube'), {'apiVersion': 'v1', 'clusters': [], 'contexts': [], 'users': []})
        ...                 with mock.patch('create_uniq_kubeconfig.write_output'):
        ...                     main(argv)
        0
    """
    args = parse_args(argv)
    setup_logging(args.verbose)

    kubeconfig_paths = [Path(p).expanduser().resolve() for p in args.kubeconfigs]
    for path in kubeconfig_paths:
        if not path.exists():
            LOGGER.error(_("Input kubeconfig not found: %s"), path)
            return 1

    output_path = Path(args.output).expanduser().resolve()
    if output_path.exists():
        if not confirm_overwrite(output_path):
            LOGGER.warning(_("Aborted: output file already exists"))
            return 1

    try:
        flattened = [flatten_kubeconfig(path) for path in kubeconfig_paths]
    except KubectlError:
        return 1
    except RuntimeError as exc:
        LOGGER.error(str(exc))
        return 1

    merged = merge_configs(flattened)
    write_output(output_path, merged)

    LOGGER.info(
        _("Merged %d kubeconfig files into %s"),
        len(flattened),
        output_path,
    )
    return 0


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    sys.exit(main())
